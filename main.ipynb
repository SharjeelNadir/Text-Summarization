{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook demonstrates how to preprocess a dataset, tokenize the text, and train a summarization model using the Hugging Face Transformers library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sharjeel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We will load the dataset from a Parquet file and display the first few rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"hf://datasets/LeaBresson/pubmed-summarization-sample2/data/train-00000-of-00001-05afa88fda9ec5a7.parquet\"\n",
    "df = pd.read_parquet(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to csv and loading it into data frame \n",
    "df.to_csv('new.csv', index=False)\n",
    "df = pd.read_csv('new.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Before tokenizing, we will handle any missing data and save the dataset to a CSV file if necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Initialize the tokenizer and define a function to tokenize the inputs and outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    inputs = [\"summarize: \" + doc for doc in examples['article']]\n",
    "    model_inputs = tokenizer(inputs, truncation=True, padding='max_length', max_length=512)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['abstract'], truncation=True, padding='max_length', max_length=128)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert and Tokenize Dataset\n",
    "\n",
    "Convert the DataFrame to a Dataset object and apply the tokenization function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to Dataset and tokenize\n",
    "dataset = Dataset.from_pandas(df)\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model and Training Arguments\n",
    "\n",
    "Load the model and set up training arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train'].select(range(1000))  # Use only the first 1000 examples for training\n",
    "eval_dataset = train_test_split['test'].select(range(200))     # Use only the first 200 examples for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_steps=500,\n",
    "    num_train_epochs=3,\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "Set up the trainer with the model, tokenizer, and training arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Trained and Stored "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "trainer.train()\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(results)\n",
    "# Save the trained model\n",
    "trainer.save_model('./fine-tuned-model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Model By giving multiple Inputs and Checking for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Passage:\n",
      "\n",
      "Cancer is a complex disease involving multiple genetic and environmental factors. The most common types include breast, lung, prostate, and colorectal cancers. Recent advancements in genomics have led to a better understanding of the molecular mechanisms underlying cancer development and progression. Targeted therapies, which are drugs designed to specifically attack cancer cells without harming normal cells, have shown promising results in clinical trials. Immunotherapy, which harnesses the body's immune system to fight cancer, has also emerged as a revolutionary treatment option. However, challenges such as drug resistance and tumor heterogeneity remain significant hurdles. Ongoing research aims to address these issues by developing more effective and personalized treatment strategies. The integration of artificial intelligence and machine learning in cancer research is expected to further accelerate the discovery of novel therapeutic targets and improve patient outcomes.\n",
      "\n",
      "\n",
      "Summarized Passage:\n",
      "targeted therapies, which are drugs designed to specifically attack cancer cells without harming normal cells, have shown promising results in clinical trials. however, challenges such as drug resistance and tumor heterogeneity remain significant hurdles. the integration of artificial intelligence and machine learning in cancer research is expected to further accelerate the discovery of novel therapeutic targets and improve patient outcomes.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_dir = './fine-tuned-model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize(text):\n",
    "    # Prepare the input\n",
    "    input_text = \"summarize: \" + text\n",
    "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\", truncation=True, padding='longest', max_length=1024)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs, \n",
    "        max_length=150,  # Adjusted max_length\n",
    "        min_length=50,   # Adjusted min_length to ensure better summarization\n",
    "        length_penalty=2.0, \n",
    "        num_beams=10,    # Increased num_beams to improve quality\n",
    "        no_repeat_ngram_size=3,  # Ensure no repeated n-grams\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example passage\n",
    "example_passage = \"\"\"\n",
    "Cancer is a complex disease involving multiple genetic and environmental factors. The most common types include breast, lung, prostate, and colorectal cancers. Recent advancements in genomics have led to a better understanding of the molecular mechanisms underlying cancer development and progression. Targeted therapies, which are drugs designed to specifically attack cancer cells without harming normal cells, have shown promising results in clinical trials. Immunotherapy, which harnesses the body's immune system to fight cancer, has also emerged as a revolutionary treatment option. However, challenges such as drug resistance and tumor heterogeneity remain significant hurdles. Ongoing research aims to address these issues by developing more effective and personalized treatment strategies. The integration of artificial intelligence and machine learning in cancer research is expected to further accelerate the discovery of novel therapeutic targets and improve patient outcomes.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarize(example_passage)\n",
    "print(\"Original Passage:\")\n",
    "print(example_passage)\n",
    "print(\"\\nSummarized Passage:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Passage:\n",
      "\n",
      "In the heart of the bustling city, where skyscrapers kissed the clouds and neon lights painted the night sky, there existed a small, unassuming bookstore. Its weathered sign, barely hanging on, proclaimed \"Whispering Pages\" in faded gold lettering. Inside, the air was thick with the scent of aging paper and ink, a comforting fragrance for the soul-weary. Tall bookshelves lined every wall, bending under the weight of their literary treasures. Dust motes danced lazily in the shafts of sunlight that streamed through the small, round windows.The proprietor, Mr. Everly, a man of gentle demeanor with wisps of gray hair framing his kind face, greeted each visitor with a warm smile. His passion for books was infectious, evident in the way he spoke about each volume as if it held a secret waiting to be discovered. Regular patrons, a diverse crowd ranging from young students seeking knowledge to elderly bibliophiles seeking solace, found solace in the quiet corners of the store. Some lost themselves in ancient tomes, while others found new adventures in freshly printed novels.Outside, the world hurried by, oblivious to the sanctuary of stories nestled within Whispering Pages. For within those hallowed walls, time slowed and the imagination soared, transcending the boundaries of reality. Each page turned whispered tales of love and loss, of heroes and villains, binding together the souls of those who dared to tread its worn wooden floors.\n",
      "\n",
      "\n",
      "Summarized Passage:\n",
      "\"Whispering Pages\" was a small, unassuming bookstore in the heart of the bustling city. it was a small, unassuming bookstore with a weathered sign, barely hanging on, proclaimed \"Whispering Pages\" in faded gold lettering. the proprietor, Mr. Everly, a man of gentle demeanor with wisps of gray hair framing his kind face, greeted each visitor with warm smile.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_dir = './fine-tuned-model'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n",
    "\n",
    "# Function to summarize text\n",
    "def summarize(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(\n",
    "        \"summarize: \" + text,\n",
    "        truncation=True,\n",
    "        padding='longest',\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        max_length=150,\n",
    "        min_length=40,\n",
    "        length_penalty=1.0,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode and return the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example passage\n",
    "example_passage = \"\"\"\n",
    "In the heart of the bustling city, where skyscrapers kissed the clouds and neon lights painted the night sky, there existed a small, unassuming bookstore. Its weathered sign, barely hanging on, proclaimed \"Whispering Pages\" in faded gold lettering. Inside, the air was thick with the scent of aging paper and ink, a comforting fragrance for the soul-weary. Tall bookshelves lined every wall, bending under the weight of their literary treasures. Dust motes danced lazily in the shafts of sunlight that streamed through the small, round windows.The proprietor, Mr. Everly, a man of gentle demeanor with wisps of gray hair framing his kind face, greeted each visitor with a warm smile. His passion for books was infectious, evident in the way he spoke about each volume as if it held a secret waiting to be discovered. Regular patrons, a diverse crowd ranging from young students seeking knowledge to elderly bibliophiles seeking solace, found solace in the quiet corners of the store. Some lost themselves in ancient tomes, while others found new adventures in freshly printed novels.Outside, the world hurried by, oblivious to the sanctuary of stories nestled within Whispering Pages. For within those hallowed walls, time slowed and the imagination soared, transcending the boundaries of reality. Each page turned whispered tales of love and loss, of heroes and villains, binding together the souls of those who dared to tread its worn wooden floors.\n",
    "\"\"\"\n",
    "\n",
    "# Generate and print the summary\n",
    "summary = summarize(example_passage)\n",
    "print(\"Original Passage:\")\n",
    "print(example_passage)\n",
    "print(\"\\nSummarized Passage:\")\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
